{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting FRB\n",
      "  Downloading https://files.pythonhosted.org/packages/48/ce/db08a6ee92b6b0eeb71f9ddbab45177488a579ce8d5600a7b7884ed97d36/FRB-1.1.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pandas in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from FRB) (0.23.4)\n",
      "Requirement already satisfied: pytz>=2011k in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from pandas->FRB) (2018.7)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from pandas->FRB) (1.16.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from pandas->FRB) (2.8.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas->FRB) (1.11.0)\n",
      "Installing collected packages: FRB\n",
      "Successfully installed FRB-1.1.4\n",
      "\u001b[33mWARNING: You are using pip version 19.2.2, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install FRB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "default_store = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AmlCompute(workspace=Workspace.create(name='AYTML', subscription_id='ea632140-cfc8-4028-bf65-ae3111412de0', resource_group='AYTML-rg'), name=cpu-cluster2, id=/subscriptions/ea632140-cfc8-4028-bf65-ae3111412de0/resourceGroups/AYTML-rg/providers/Microsoft.MachineLearningServices/workspaces/AYTML/computes/cpu-cluster2, type=AmlCompute, provisioning_state=Succeeded, location=eastus2, tags=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "\n",
    "aml_compute = ws.get_default_compute_target(\"CPU\")\n",
    "\n",
    "if aml_compute is None:\n",
    "    amlcompute_cluster_name = \"cpu-cluster2\"\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D3_V2\",\n",
    "                                                                admin_username='admin',\n",
    "                                                                admin_user_password='pass',\n",
    "                                                                max_nodes = 4)\n",
    "\n",
    "    aml_compute = ComputeTarget.create(ws, amlcompute_cluster_name, provisioning_config)\n",
    "    aml_compute.wait_for_completion(show_output = True, min_node_count = None, timeout_in_minutes = 20)\n",
    "\n",
    "aml_compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 'auto_prepare_environment' is deprecated and unused. It will be removed in a future release.\n",
      "WARNING - 'auto_prepare_environment' is deprecated and unused. It will be removed in a future release.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run configuration created.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "# Create a new runconfig object\n",
    "aml_run_config = RunConfiguration()\n",
    "\n",
    "# Use the aml_compute you created above. \n",
    "aml_run_config.target = aml_compute\n",
    "\n",
    "# Enable Docker\n",
    "aml_run_config.environment.docker.enabled = True\n",
    "\n",
    "# Set Docker base image to the default CPU-based image\n",
    "aml_run_config.environment.docker.base_image = \"mcr.microsoft.com/azureml/base:0.2.1\"\n",
    "\n",
    "# Use conda_dependencies.yml to create a conda environment in the Docker image for execution\n",
    "aml_run_config.environment.python.user_managed_dependencies = False\n",
    "\n",
    "# Auto-prepare the Docker image when used for execution (if it is not already prepared)\n",
    "aml_run_config.auto_prepare_environment = True\n",
    "\n",
    "# Specify CondaDependencies obj, add necessary packages\n",
    "aml_run_config.environment.python.conda_dependencies = CondaDependencies.create(\n",
    "    conda_packages=['pandas','scikit-learn'], \n",
    "    pip_packages=['azureml-sdk', 'azureml-dataprep', 'azureml-train-automl', 'FRB'], \n",
    "    pin_sdk_version=False)\n",
    "\n",
    "print (\"Run configuration created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Alchemy Engine created\n"
     ]
    }
   ],
   "source": [
    "## Get Data Locally\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/nbuser/library/')\n",
    "from Ingestion import create_sql_engine\n",
    "dataDir = \"data\"\n",
    "\n",
    "if not os.path.exists(dataDir):\n",
    "    os.mkdir(dataDir)\n",
    "    \n",
    "engine = create_sql_engine(uid='database_login', password='password-123')\n",
    "DATABASE_TABLES = ['RATES', 'INFLATION']#, 'ECONOMY', 'CREDIT', 'AGRICULTURE']\n",
    "for t in DATABASE_TABLES:\n",
    "    curr_data = dataDir + f\"/curr_data/{t}\"\n",
    "\n",
    "    if not os.path.exists(curr_data):\n",
    "        os.mkdir(curr_data)\n",
    "\n",
    "#engine = create_sql_engine(uid='database_login', password='password-123')\n",
    "\n",
    "    query = 'SELECT * FROM [dbo].[{table}_Cleaned]'.format(table=t)\n",
    "    df = pd.read_sql(query, engine, index_col='index')\n",
    "    #Add group by to agg\n",
    "    df.to_csv(f'./data/curr_data/{t}/Cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading ./data/curr_data/RATES/Cleaned.csv\n",
      "Uploaded ./data/curr_data/RATES/Cleaned.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_51111766944d4f7c9e809193c3feda42"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_store.upload_files(['./data/curr_data/RATES/Cleaned.csv'], \n",
    "                           target_path = 'RATES', \n",
    "                           overwrite = True, \n",
    "                           show_progress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate script is in /home/nbuser/library/scripts/prepdata.\n",
      "aggRatesStep created.\n"
     ]
    }
   ],
   "source": [
    "from azureml.data.data_reference import DataReference \n",
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "import os\n",
    "# python scripts folder\n",
    "prepare_data_folder = './scripts/prepdata'\n",
    "\n",
    "blob_rates_data = DataReference(\n",
    "    datastore=default_store,\n",
    "    data_reference_name=\"agg_rates_data\",\n",
    "    path_on_datastore=\"RATES/Cleaned.csv\")\n",
    "\n",
    "# Define output after cleansing step\n",
    "agg_rates_data = PipelineData(\"agg_rates_data\", datastore=default_store)\n",
    "\n",
    "print('Aggregate script is in {}.'.format(os.path.realpath(prepare_data_folder)))\n",
    "\n",
    "# cleansing step creation\n",
    "# See the cleanse.py for details about input and output\n",
    "aggRatesStep = PythonScriptStep(\n",
    "    name=\"agg_rates_data\",\n",
    "    script_name=\"agg.py\", \n",
    "    arguments=[\"--input_cleanse\", blob_rates_data, \n",
    "               \"--output_cleanse\", agg_rates_data],\n",
    "    inputs=[blob_rates_data],\n",
    "    outputs=[agg_rates_data],\n",
    "    compute_target=aml_compute,\n",
    "    runconfig=aml_run_config,\n",
    "    source_directory=prepare_data_folder,\n",
    "    allow_reuse=True\n",
    ")\n",
    "\n",
    "print(\"aggRatesStep created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading ./data/curr_data/INFLATION/Cleaned.csv\n",
      "Uploaded ./data/curr_data/INFLATION/Cleaned.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_bbd11ea67a0947ef8532766f2e32b4a9"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_store.upload_files(['./data/curr_data/INFLATION/Cleaned.csv'], \n",
    "                           target_path = 'INFLATION', \n",
    "                           overwrite = True, \n",
    "                           show_progress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate script is in /home/nbuser/library/scripts/prepdata.\n",
      "aggInflationStep created.\n"
     ]
    }
   ],
   "source": [
    "from azureml.data.data_reference import DataReference \n",
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "# python scripts folder\n",
    "prepare_data_folder = './scripts/prepdata'\n",
    "\n",
    "blob_inflation_data = DataReference(\n",
    "    datastore=default_store,\n",
    "    data_reference_name=\"inflation_data\",\n",
    "    path_on_datastore=\"INFLATION/Cleaned.csv\")\n",
    "\n",
    "# Define output after cleansing step\n",
    "agg_inflation_data = PipelineData(\"inflation_data\", datastore=default_store)\n",
    "\n",
    "print('Aggregate script is in {}.'.format(os.path.realpath(prepare_data_folder)))\n",
    "\n",
    "# cleansing step creation\n",
    "# See the cleanse.py for details about input and output\n",
    "aggInflationStep = PythonScriptStep(\n",
    "    name=\"Aggregate Inflation Data\",\n",
    "    script_name=\"agg.py\", \n",
    "    arguments=[\"--input_cleanse\", blob_inflation_data, \n",
    "               \"--output_cleanse\", agg_inflation_data],\n",
    "    inputs=[blob_inflation_data],\n",
    "    outputs=[agg_inflation_data],\n",
    "    compute_target=aml_compute,\n",
    "    runconfig=aml_run_config,\n",
    "    source_directory=prepare_data_folder,\n",
    "    allow_reuse=True\n",
    ")\n",
    "\n",
    "print(\"aggInflationStep created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline is built.\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "pipeline_steps=[aggRatesStep,aggInflationStep]\n",
    "pipeline = Pipeline(workspace = ws, steps=pipeline_steps)\n",
    "print(\"Pipeline is built.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment created\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment = Experiment(ws,'FRED_Experiment')\n",
    "\n",
    "print(\"Experiment created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step agg_rates_data [473d35d7][cb846918-b794-4184-a4f4-805993f852be], (This step will run and generate new outputs)\n",
      "Created step Aggregate Inflation Data [2a4675ee][1f1ee6de-87ca-4dbb-816c-6d4876867fc0], (This step is eligible to reuse a previous run's output)\n",
      "Using data reference INPUT_agg_rates_data for StepId [a96cd663][a4c1cdee-5427-4f25-9d37-98d223ecc85a], (Consumers of this data are eligible to reuse prior runs.)\n",
      "Using data reference INPUT_inflation_data for StepId [8b53551a][fa0a5b59-bdbd-44ac-a257-181867a43276], (Consumers of this data are eligible to reuse prior runs.)\n",
      "Submitted pipeline run: e64860df-f4e3-40f4-803b-30a4c941fceb\n",
      "Pipeline submitted for execution.\n"
     ]
    }
   ],
   "source": [
    "pipeline_run = experiment.submit(pipeline, regenerate_outputs=False)\n",
    "\n",
    "print(\"Pipeline submitted for execution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb5829f018b64157931e7ffd40508a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "668cf333dc6742a99d5e1e01b080dcf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RunDetails(pipeline_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Aggregated Rates Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: e64860df-f4e3-40f4-803b-30a4c941fceb\n",
      "Link to Portal: https://mlworkspace.azure.ai/portal/subscriptions/ea632140-cfc8-4028-bf65-ae3111412de0/resourceGroups/AYTML-rg/providers/Microsoft.MachineLearningServices/workspaces/AYTML/experiments/FRED_Experiment/runs/e64860df-f4e3-40f4-803b-30a4c941fceb\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': 'e64860df-f4e3-40f4-803b-30a4c941fceb', 'status': 'Completed', 'startTimeUtc': '2019-11-08T17:35:47.870741Z', 'endTimeUtc': '2019-11-08T17:42:03.55306Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': None, 'runType': 'HTTP', 'azureml.parameters': '{}'}, 'logFiles': {'logs/azureml/executionlogs.txt': 'https://aytml9430632465.blob.core.windows.net/azureml/ExperimentRun/dcid.e64860df-f4e3-40f4-803b-30a4c941fceb/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=JRk9D7Xno7fgSuALoUy6YvNNXUaWlRzCdxU2FFaLgWo%3D&st=2019-11-08T17%3A32%3A16Z&se=2019-11-09T01%3A42%3A16Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://aytml9430632465.blob.core.windows.net/azureml/ExperimentRun/dcid.e64860df-f4e3-40f4-803b-30a4c941fceb/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=%2BYVILT%2BCLneQj4pHQSFvu3RGKjgM9qg5nSmFgetfX38%3D&st=2019-11-08T17%3A32%3A16Z&se=2019-11-09T01%3A42%3A16Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://aytml9430632465.blob.core.windows.net/azureml/ExperimentRun/dcid.e64860df-f4e3-40f4-803b-30a4c941fceb/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=pWUqVmx7T7%2F8LrZPyYLxyP7cQJaFis1vPG%2B07QXZFWE%3D&st=2019-11-08T17%3A32%3A16Z&se=2019-11-09T01%3A42%3A16Z&sp=r'}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Before we proceed we need to wait for the run to complete.\n",
    "pipeline_run.wait_for_completion()\n",
    "\n",
    "import azureml.dataprep as dprep\n",
    "# functions to download output to local and fetch as dataframe\n",
    "def get_download_path(download_path, output_name):\n",
    "    output_folder = os.listdir(download_path + '/azureml')[0]\n",
    "    path =  download_path + '/azureml/' + output_folder + '/' + output_name\n",
    "    return path\n",
    "\n",
    "def fetch_df(step, output_name):\n",
    "    output_data = step.get_output_data(output_name)\n",
    "    \n",
    "    download_path = './outputs/' + output_name\n",
    "    output_data.download(download_path)\n",
    "    df_path = get_download_path(download_path, output_name) + '/part-00000'\n",
    "    return dprep.auto_read_file(path=df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agg_rates_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Path already exists. Skipping download for ./outputs/agg_rates_data/azureml/bf143824-a73b-4730-b010-7ede5a73722b/agg_rates_data/_SUCCESS\n",
      "WARNING - Path already exists. Skipping download for ./outputs/agg_rates_data/azureml/bf143824-a73b-4730-b010-7ede5a73722b/agg_rates_data/part-00000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1962-01-01</td>\n",
       "      <td>4.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1962-04-01</td>\n",
       "      <td>3.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1962-07-01</td>\n",
       "      <td>4.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1962-10-01</td>\n",
       "      <td>4.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1963-01-01</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      period  value\n",
       "0 1962-01-01   4.08\n",
       "1 1962-04-01   3.95\n",
       "2 1962-07-01   4.06\n",
       "3 1962-10-01   4.07\n",
       "4 1963-01-01   4.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agg_Rates_Step = pipeline_run.find_step_run(aggRatesStep.name)[0]\n",
    "print(aggRatesStep.name)\n",
    "agg_Rates_df = fetch_df(agg_Rates_Step, agg_Rates_Step.name)\n",
    "display(agg_Rates_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Train and Test DataFlows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(agg_Rates_df.row_count * 0.8)\n",
    "p_df=agg_Rates_df.to_pandas_dataframe()\n",
    "train_data=p_df[:int(len(p_df) * 0.8)]\n",
    "test_data=p_df[int(len(p_df) * 0.8):]\n",
    "label='value'\n",
    "#test_labels = test_data.pop(label)\n",
    "\n",
    "X=train_data['period'].values\n",
    "y=train_data['value'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoML Step Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.automl import AutoMLConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "time_series_settings = {\n",
    "    \"time_column_name\": \"period\",\n",
    "    \"max_horizon\": 50\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(task='forecasting',\n",
    "                             primary_metric='normalized_root_mean_squared_error',\n",
    "                             experiment_timeout_minutes=15,\n",
    "                             enable_early_stopping=True,\n",
    "                             X=train_data,\n",
    "                             y=y,\n",
    "                             label='value',\n",
    "                             n_cross_validations=5,\n",
    "                             enable_ensembling=False,\n",
    "                             verbosity=logging.INFO,\n",
    "                             **time_series_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment created\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_aml = Experiment(ws,'FRED_Experiment_AutoML')\n",
    "\n",
    "print(\"Experiment created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local machine\n",
      "Parent Run ID: AutoML_a4c48a8c-da19-4fa1-8b07-720098456381\n",
      "Current status: DatasetFeaturization. Beginning to featurize the dataset.\n",
      "Current status: DatasetFeaturizationCompleted. Completed featurizing the dataset.\n",
      "Current status: DatasetCrossValidationSplit. Generating CV splits.\n",
      "Current status: DatasetFeaturization. Beginning to featurize the CV split.\n",
      "Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.\n",
      "Current status: DatasetFeaturization. Beginning to featurize the CV split.\n",
      "Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.\n",
      "Current status: DatasetFeaturization. Beginning to featurize the CV split.\n",
      "Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.\n",
      "Current status: DatasetFeaturization. Beginning to featurize the CV split.\n",
      "Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.\n",
      "Current status: DatasetFeaturization. Beginning to featurize the CV split.\n",
      "Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         0   RobustScaler ElasticNet                        0:02:26       0.0680    0.0680\n",
      "         1   StandardScalerWrapper ElasticNet               0:00:49       0.0812    0.0680\n",
      "         2   StandardScalerWrapper ElasticNet               0:00:51       0.0236    0.0236\n",
      "         3   StandardScalerWrapper RandomForest             0:01:19       0.1308    0.0236\n",
      "         4   StandardScalerWrapper LightGBM                 0:00:51       0.1426    0.0236\n",
      "         5   StandardScalerWrapper LassoLars                0:00:48       0.0011    0.0011\n",
      "         6   MinMaxScaler DecisionTree                      0:00:50       0.0440    0.0011\n",
      "         7   MaxAbsScaler RandomForest                      0:00:54       0.1195    0.0011\n",
      "         8   MaxAbsScaler DecisionTree                      0:00:54       0.1302    0.0011\n",
      "         9   MinMaxScaler DecisionTree                      0:00:56       0.0645    0.0011\n",
      "        10   StandardScalerWrapper DecisionTree             0:00:56       0.0260    0.0011\n",
      "        11   MinMaxScaler ExtremeRandomTrees                0:01:38       0.0827    0.0011\n",
      "        12   MinMaxScaler ExtremeRandomTrees                0:00:54       0.1170    0.0011\n",
      "        13   StandardScalerWrapper ElasticNet               0:00:47       0.0086    0.0011\n",
      "        14   StackEnsemble                                  0:01:28       0.0002    0.0002\n",
      "Stopping criteria reached at iteration 14. Ending experiment.Pipeline submitted for execution.\n"
     ]
    }
   ],
   "source": [
    "pipeline_run_aml = experiment_aml.submit(automl_config, show_output=True)\n",
    "\n",
    "print(\"Pipeline submitted for execution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline_run_aml = experiment_aml.submit(automl_config, show_output=True)\n",
    "\n",
    "best_run, fitted_model = pipeline_run_aml.get_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_labels = test_data['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_labels = fitted_model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006182752934849445"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "rmse = sqrt(mean_squared_error(actual_labels, predict_labels))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>FRED_Experiment_AutoML</td><td>AutoML_a4c48a8c-da19-4fa1-8b07-720098456381_14</td><td></td><td>Completed</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/ea632140-cfc8-4028-bf65-ae3111412de0/resourceGroups/AYTML-rg/providers/Microsoft.MachineLearningServices/workspaces/AYTML/experiments/FRED_Experiment_AutoML/runs/AutoML_a4c48a8c-da19-4fa1-8b07-720098456381_14\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run.Run?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: FRED_Experiment_AutoML,\n",
       "Id: AutoML_a4c48a8c-da19-4fa1-8b07-720098456381_14,\n",
       "Type: None,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
